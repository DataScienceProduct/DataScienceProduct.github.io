









[{"categories":["Product Management"],"contents":"In a first article, I introduced what data science product management was about and why it is important. In this article, I would like to introduce a framework on how you can achieve building a valuable data science product, based on my personal experience and inspired by design processes.\nMany companies are building data science products that aim to help users. Apple’s Siri, Netflix’s movie recommendations, and Amazon\u0026rsquo;s product recommendations are prime examples. They are designed to provide advice, recommendations, or automating repetitive human tasks, and so on. One important point to remember is that products powered by data science are not deterministic. They may behave differently in contexts that may look similar and they make mistakes; so how do we ensure that these mistakes don\u0026rsquo;t end up impacting us badly? Netflix recommendation engine is personalized. It won’t recommend the same shows or movies compared to other profiles with similar history if you only watch thrillers or comedies! Amazon will recommend new books based on your purchase history. If they recommend a bad movie or a bad product, it\u0026rsquo;s not a big deal, we move on. But what happens if it is a product that identifies cancer cells inaccurately, the consequences can be very serious!\nThe recipe for building valuable products always includes the same main steps:\n Discover the right problem to solve Deliver a valuable, feasible and desirable (right) solution that delivers business outcomes  To give you a sense of how important this topic is, know that Gartner predicted, back in 2019, that in 2022 only 20% of analytics insights would deliver business outcomes.\nAs simple as these two steps may seem, a common mistake I often made was to think of solutions before I clearly identified the problem to solve. You must first identify the proper problem to solve and only then defining a solution is essential to develop a successful product i.e. a product that achieves market fit, brings business value and solves user pain points. However this process is not fully linear. It is an iterative and continuous flow between the discovery (identifying problems to solve), experimentation and testing of potential solutions.\nMarty Cagan explains it very simply in Inspired:\n Customers don’t know what is possible, and with technology products, none of us know what we really want until we actually see it.\n My goal for the rest of this article is to walk you through a framework that formalizes a process you can follow to guide you from discovery (identifying problems), to delivery (shipping the product that solves the specific problem at stake). This framework is adapted to the specificities of business problems one wants to solve with data science and analytics. Also, you should not follow it by the letter but rather as a set of guidelines on what to focus on at every step of the process. I’ll use a real life example, a product I shipped at a previous job as an example to help you get a more concrete sense of how this framework can be used.\nBefore walking you through the main steps, let me share with you the origin of this framework. It is based on the \u0026ldquo;double diamond\u0026rdquo; design process model developed by the Design Council in 2005 (updated in 2019). Divided into four distinct stages – Discover, Define, Develop and Deliver – it symbolizes the divergent (exploring business opportunities) and convergent mindsets (focusing team effort to delivering them). It is well suited to product management at any maturity in product development.\nThe first diamond stands for the problem space, which aims to have a deep understanding of our market, our users, their issues and their challenges. When a problem is defined and measured, it becomes an opportunity.\nThe second diamond stands for the delivery space. It starts with a diverging phase with development and converging phase with delivering a solution that solves the single problem defined and refined during the previous stage.\nFig. 1: Double diamond  Fig. 2: Team implication  Switching between exploration with divergent thinking and converging into focused deliveries This framework begins with a desired business outcome aligned with company strategy: increase revenue by 10%, increase retention rate by 5 points, reduce potential loss by 10%, etc. Starting with this outcome in mind, we can truly understand our user context and deliver a solution that creates value.\nLet me illustrate how we achieved reducing significantly the number of fraudulent cases and potential loss, with a fraud detection product that my team and I built. We had a clear business outcome to achieve: reduce potential loss by x percent. We identified main losses through user interviews and data analysis. Based on these findings, we decided to solve this issue and build a dedicated product to help our users to identify fraudulent cases before losing money. How did we do it?\n We DISCOVERED that amounts lost to fraud were impressive, fraud investigation was really painful and time consuming for users! We spent a lot of time understanding our users: what are their objectives, what are their daily challenges, what issues are they facing? We also shadowed them to uncover additional pain points. We DEFINED this problem by estimating potential impacts in terms of users, time saved, loss reduction and effort needed to build it. We identified that detecting potential frauds is a great opportunity to seize to reduce potential loss. It was one of the most promising opportunities among those discovered. We DEVELOPED potential solutions and tested them with users. We DELIVERED the solution that performed the best in detecting potential frauds during our test and carried on monitoring the impacts.  I will call this product Detective Chimp in the remaining part of my article :)\nHow do we DISCOVER pain points to solve? In the first step of this framework, we build up a portfolio of potential opportunities that might drive business outcomes. A crucial attitude to have here is to be as open as possible without limiting yourself. It is called a diverging phase. We need to keep our perspectives wide open to allow for a broad range. It helps us understand without being biased what opportunities and problems our users are really facing. It involves conducting research by analyzing the market, speaking to and spending time with users who are directly affected. Success metrics are detailed along with the findings to quantify the opportunities.\nThe purpose of this phase is to address critical risks when an opportunity is discovered:\n Is it valuable for users? Would they buy it? Does it improve our outcomes? (viability) Is it usable and desirable for users? (usability and desirability) Do we have data? Is it accessible? Is the sample extracted representative? How is the quality? (scientific feasibility) Can we build it? How much effort is needed? (technical feasibility)  For Detective Chimp, we looked at how valuable it was for our users to help them with fraud detection, how desirable it would be, what data we have and how difficult it is.\nLet me share another example I like that illustrates scientific feasibility: During World War II, US bombers suffered badly from German air defense. One option was to add more armor. More armor means more weight, and adding too much would reduce maneuverability and increase fuel consumption. So, the US military reached the Statistical Research Group (SRG) at Columbia University with, by asking, “how much armor should we use for optimal results, and where should we put it?”\nOnly some data was provided such as the number of hits and their location on returning aircraft. The sample showed that damage wasn’t uniformly distributed, more bullet holes in the fuselage, not so many in the engines. US military was expecting to reinforce with additional armor the locations with the highest number of bullet holes – the fuselage.\nAbraham Wald – a mathematician from SRG who was assigned to solve this problem – figured out the samples were missing aircraft that didn’t come back. He understood that the sample was not representative and recommended increasing armor in the areas that showed the least damage – the engine.\nThis story shows the importance of fully understanding the dataset acquired during discovery. The most important point that Abraham Wald verified is representativity of the sample provided by the US Army. If he didn’t verify it, it would have reinforced the fuse and wouldn’t have solved the initial problem.\nHow do we DEFINE the opportunity to seize? In this second step, we methodologically prioritize the most promising opportunities among those in the portfolio that don’t provide any value for their effort. It is a converging phase which brings team alignment and focus on a single business opportunity to be developed. It ends with a clear definition and actual measurement of the problem to be solved.\nTo do so, we relied on prioritization techniques based on different criterias that define the value and costs of this opportunity.\nOne that works well for me with data science products is RICE, developed by Intercom. I won’t detail the method here (Intercom did it very well!) but in a nutshell for Detective Chimp, we answered the questions:\n Reach: How many users will this opportunity impact over a time period? Impact: How much will this opportunity impact the desired outcomes when the opportunity is fulfilled? Confidence: How confident are you about your answers? Effort: How complex is it to seize this opportunity in terms of design, engineering and data science?  We estimated all these factors based on the findings from discovery phase:\n Reach: we measured the number of events per month and our the total number of users Impact: based on our data analysis, we scored this opportunity as the highest among all our opportunities Confidence: we had a high level of confidence based on our discovery that we would definitely help our users in this specific problem Effort: all the product team estimated the work needed to improve fraud detection and it would take months  Once estimated, we combined these factors into a single score through a formula:\n(Reach * Impact * Confidence) / Effort We compared together all opportunities identified at a glance and a clear idea of what to develop next.\nIn addition, statistical techniques can significantly provide additional value in assessing opportunities identified. We can directly test our assumptions against quantitative evidence to define which one are most impactful. For example, we used descriptive statistics to quantify the problem that we were trying to solve with Detective Chimp: how often does fraud occur? How much do we lose? What is the mean amount we lose? How many cases can we prevent?\nHow do we DEVELOP the right solution for the opportunity identified? In the third step, we brainstorm with an open mind potential solutions for our business opportunities, develop prototypes to learn something at a lower cost, and measure their potential benefits. We undergo extensive iteration with users to ensure that they have fully addressed business opportunities uncovered during our discovery.\nFor Detective Chimp, we started to develop simple machine learning prototypes, built data pipelines, designed user experience and mock-ups. We tested it with users and measured the impact (in terms of model performance, usability and viability). We did it until we were satisfied with the result, then we delivered it to users :)!\nI identified key specificities for developing the right data (science) product from brainstorming solutions, prototyping and testing:\n During a brainstorming session, we need to take into consideration how the data will be acquired, transformed, stored and exploited: when our fraud algorithm will be triggered? How is it displayed? How will our users exploit it?. It depends on the context, the availability of the data and the problem to be solved. During prototyping, user journeys, mockup interfaces and little code are generally built for digital products. How the data is processed remains a key difference in data products here. My personal conviction is that simple logic rules (e.g. counting a specific event that most fraudsters relied on) can provide more benefits than a machine learning model in some context; Before Detective Chimp was designed, simple user-defined ratios were used to roughly detect fraudulent cases. We developed a better prediction model through iterations. When a prototype is ready, it is time to get feedback from our users about how it addresses their needs. It is a good opportunity to test deeply how sensitive users are to error and how critical it is. For Detective Chimp, we wanted to be as accurate as possible to avoid harmful surprises with false positives (e.g. case identified as fraudulent but in reality, it is not)  In the end, the best prototypes we developed to solve our initial problem are delivered to users during the last stage. After model performance, the biggest challenges are how to access and process large amounts of data. They don’t only impact prototypes, but also have a large influence in the quality of the solution.\nHow do we DELIVER the right solution to our users? Delivering data science models is a challenging topic in itself. They are unique because of their highly specialized requirements for production lifecycle management. For instance, what happens when your data changes? What happens when our predictions change? What happens when human processes change? How do we know that our prediction was incorrect? Dedicated articles will focus deeply on this aspect.\nWell, once released and impact measured, we arrived at the end of this double diamond journey. When Detective Chimp was launched, we closely monitored during the first months: how many users used it (Reach)? How many fraud cases did we detect and prevent? How much did it impact our desired outcomes (Impact)? In less than one year, we reduced potential loss greatly by reducing the number of fraudulent cases.\nThis is not a linear voyage, a new one will start all over again with new improvements. However, new findings in data can send us back to the beginning (but with more experience). Making and testing very early stage ideas can be part of discovery.\nMy last advice to finish this first part, iterate!\nA second part will go into more details about product management and data science lifecycle.\nSource:  https://blogs.gartner.com/andrew_white/2019/01/03/our-top-data-and-analytics-predicts-for-2019/ https://svpg.com/four-big-risks/ https://en.wikipedia.org/wiki/Survivorship_bias https://medium.com/@penguinpress/an-excerpt-from-how-not-to-be-wrong-by-jordan-ellenberg-664e708cfc3d http://www.ams.org/publicoutreach/feature-column/fc-2016-06  ","date":"29 Mar, 2022","image":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cpicture\u003e\n  \u003csource srcset=\"/images/post/02_hu1cc87033e8914d791e89f67899168b44_13189285_545x0_resize_q95_h2_box_3.webp\" media=\"(max-width: 575px)\"\u003e\n  \u003csource srcset=\"/images/post/02_hu1cc87033e8914d791e89f67899168b44_13189285_600x0_resize_q95_h2_box_3.webp\" media=\"(max-width: 767px)\"\u003e\n  \u003csource srcset=\"/images/post/02_hu1cc87033e8914d791e89f67899168b44_13189285_700x0_resize_q95_h2_box_3.webp\" media=\"(max-width: 991px)\"\u003e\n  \u003csource srcset=\"/images/post/02_hu1cc87033e8914d791e89f67899168b44_13189285_1110x0_resize_q95_h2_box_3.webp\"\u003e\n  \u003cimg loading=\"lazy\" decoding=\"async\" class=\"w-100 img-fluid rounded\" src=\"/images/post/02_hu1cc87033e8914d791e89f67899168b44_13189285_1110x0_resize_box_3.png\" alt=\"\" width=\"5472\" height=\"3648\"\u003e\n\u003c/picture\u003e\n \n \n \n\n","permalink":"https://DataScienceProduct.com/blog/from-discovery-delivering-data-science-product/","tags":["Framework","Design"],"title":"From discovery to delivering a data science product"},{"categories":["Product Management"],"contents":"The main idea of this article is to introduce the specificities of a data science product management approach.\nTL;DR: Product management is the process of building a product taking into account business opportunities and solving end users’ problems. A product leveraging data science techniques to improve user experience requires specific approaches such as identifying and validating the benefits of a predictive model to solve a particular business challenge.\nOn a daily basis, whether in our professional or personal lives, talking to Siri, picking a movie to watch on Netflix, buying something on Amazon are all examples of data science being used in products. The experience is so smooth that we may have no idea that they are based on these techniques. Many industries, in various domains of activity, are using them, e.g.\n Image recognition (face detection, character detection, medical diagnosis with image processing, etc) Speech recognition (voice assistant) Recommendation (prediction for commuting, suggested word in search engine, product recommendation, etc) Anomaly detection (fraud, preventive maintenance, etc) The list of examples is way longer.  Let’s start with what product management is Product management is the process of maximizing business value and reducing operational risks by building the right product and solving the most important end users’ problem. Product managers closely collaborate with engineers and designers to identify a solution to solve end user\u0026rsquo;s problems. This collaboration between these 3 roles (Product trio) provides different expertises and perspectives which tackles main risks of building the wrong things, such as a product:\n Not viable for a market and end users (risk of viability) Not feasible (risk of feasibility) Not usable and desired by users (risk of usability and desirability).  Fig. 1: Product trio  A quote from Marty Cagan from Inspired captures this idea\n Great products require an intense collaboration with design and engineering to solve real problems for your users and customers, in ways that meet the needs of your business. In each of these examples, the users had no idea the solution they fell in love with was possible.\n Product manager\u0026rsquo;s role might vary across different types of industry and organization. Product managers are responsible for business outcomes by shaping the vision of what to build and why. Product managers’ core responsibilities involve critical tasks during product development lifecycle:\n identifying business opportunities by conducting research, setting the destination of where to go and communicating how to reach the destination with a product roadmap prioritizing development in order to maximize business value with delivery team, driving continuous development, measuring the impact and iterate  Short reminder of what data science is Data science is an interdisciplinary field that combines knowledge of mathematics (statistics,probabilities, linear algebra, …), programming skills and domain expertise to systematically extract information from data. Data Science enables a new way to provide actionable insights for users. Cassie Kozyrkov puts it in a simple word:\n Data science is the discipline of making data useful.\n Data scientist\u0026rsquo;s roles might also vary a lot during product development. Typical responsibilities for a data scientist are leveraging multiple data sources, transforming these data to insights through advanced analytics and statistical learning in order to solve business related problems (with the help of a data engineer). A typical day for a data scientist is made up of the following tasks:\n Understanding the business context and identifying opportunities that can be addressed with data Exploring which data can be used and collecting existing data sources Identifying and testing which modeling approaches could improve the desired outcome Building and prototyping identified model in order to maximize business value Deploying the model, measure the performance and iterate  Now that we have a clearer idea of what product management and data science are, let\u0026rsquo;s look at the intersection between the 2 disciplines\nSo, what is data science product management? First of all, the purpose of data science product management is the same: maximizing business value and reducing operational risks by building the right product and solving the most important end users’ problem. But, building products that rely on data science techniques comes with additional challenges. This is a somewhat distinct process from building digital products. These products are not deterministic, which means they behave differently in contexts that may look similar and they make mistakes. Users are not at ease with it in most situations.\nThis type of product requires specific skill sets for a product manager such as:\n Capacity to identify opportunities where data can be leveraged and potentially add significant value Deep understanding of the importance of data, specific data science life cycle and development phases Basic knowledge of statistics and data processing techniques to be able to prioritize development with respect to business value creation.  In the same way as digital products, great data science products require an intense collaboration between design, engineering and data science to solve real problems for your users and customers, in ways that meet the needs of your business. Data scientists complete the product trio (mentioned in the first section). They bring a strong expertise in statistical modeling and data processing techniques to the team. They tackle the risk of having a solution not scientifically feasible while the engineers address the technical feasibility.\nThe former trio becomes a quatro.\nFig. 2: Product quatro  Future articles will go into more details about problem framing, data science life cycle, user experience, testing non-deterministic features, collaboration between the 4 members of the quatro… Stay tuned!\nSource:  https://svpg.com/four-big-risks/ https://producttalk.org/2021/06/roles-in-a-product-trio/  ","date":"31 Jan, 2022","image":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cpicture\u003e\n  \u003csource srcset=\"/images/post/01_hu3710334fe391ff99d23606ed3d189e9a_2519557_545x0_resize_q95_h2_box.webp\" media=\"(max-width: 575px)\"\u003e\n  \u003csource srcset=\"/images/post/01_hu3710334fe391ff99d23606ed3d189e9a_2519557_600x0_resize_q95_h2_box.webp\" media=\"(max-width: 767px)\"\u003e\n  \u003csource srcset=\"/images/post/01_hu3710334fe391ff99d23606ed3d189e9a_2519557_700x0_resize_q95_h2_box.webp\" media=\"(max-width: 991px)\"\u003e\n  \u003csource srcset=\"/images/post/01_hu3710334fe391ff99d23606ed3d189e9a_2519557_1110x0_resize_q95_h2_box.webp\"\u003e\n  \u003cimg loading=\"lazy\" decoding=\"async\" class=\"w-100 img-fluid rounded\" src=\"/images/post/01_hu3710334fe391ff99d23606ed3d189e9a_2519557_1110x0_resize_q95_box.jpg\" alt=\"\" width=\"5472\" height=\"3648\"\u003e\n\u003c/picture\u003e\n \n \n \n\n","permalink":"https://DataScienceProduct.com/blog/what-is-data-science-product-management/","tags":["Product Management","Product Design","Data Science"],"title":"What is data science product management and why it's important"}]